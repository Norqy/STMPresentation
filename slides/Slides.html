
<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="remark,remarkjs,markdown,slideshow,presentation" />
    <meta name="description" content="A simple, in-browser, markdown-driven slideshow tool." />
    <title>Software Transactional Memory in Scala</title>
    <style type="text/css">
      @import url(http://fonts.googleapis.com/css?family=Droid+Serif);
      @import url(http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(http://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body {
        font-family: 'Droid Serif';
      }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: 400;
        margin-bottom: 0;
      }
      .remark-slide-content h1 { font-size: 3em; }
      .remark-slide-content h2 { font-size: 2em; }
      .remark-slide-content h3 { font-size: 1.6em; }
      .footnote {
        position: absolute;
        bottom: 3em;
      }
      li p { line-height: 1.25em; }
      .red { color: #fa0000; }
      .large { font-size: 2em; }
      a, a > code {
        color: rgb(249, 38, 114);
        text-decoration: none;
      }
      code {
        -moz-border-radius: 5px;
        -web-border-radius: 5px;
        background: #e7e8e2;
        border-radius: 5px;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .remark-code-line-highlighted     { background-color: #373832; }
      .pull-left {
        float: left;
        width: 47%;
      }
      .pull-right {
        float: right;
        width: 47%;
      }
      .pull-right ~ p {
        clear: both;
      }
      #slideshow .slide .content code {
        font-size: 0.8em;
      }
      #slideshow .slide .content pre code {
        font-size: 0.9em;
        padding: 15px;
      }
      .inverse {
        background: #272822;
        color: #777872;
        text-shadow: 0 0 20px #333;
      }
      .inverse h1, .inverse h2 {
        color: #f3f3f3;
        line-height: 0.8em;
      }

      /* Slide-specific styling */
      #slide-inverse .footnote {
        bottom: 12px;
        left: 20px;
      }
      #slide-how .slides {
        font-size: 0.9em;
        position: absolute;
        top:  151px;
        right: 140px;
      }
      #slide-how .slides h3 {
        margin-top: 0.2em;
      }
      #slide-how .slides .first, #slide-how .slides .second {
        padding: 1px 20px;
        height: 90px;
        width: 120px;
        -moz-box-shadow: 0 0 10px #777;
        -webkit-box-shadow: 0 0 10px #777;
        box-shadow: 0 0 10px #777;
      }
      #slide-how .slides .first {
        background: #fff;
        position: absolute;
        top: 20%;
        left: 20%;
        z-index: 1;
      }
      #slide-how .slides .second {
        position: relative;
        background: #fff;
        z-index: 0;
      }

      /* Two-column layout */
      .left-column {
        color: #777;
        width: 20%;
        height: 92%;
        float: left;
      }
        .left-column h2:last-of-type, .left-column h3:last-child {
          color: #000;
        }
      .right-column {
        width: 75%;
        float: right;
        padding-top: 1em;
      }

      .comment { display: None }

    </style>
  </head>
  <body>
    <textarea id="source">
name: inverse
layout: true
class: center, middle
---
#Software Transactional Memory for Scala
---
layout: false
class: left, middle

.left-column[
##Transactional Memory
###Agenda
]
.right-column[
##A different approach to concurrency
- Problem description
- Conventional solutions
- Transactional memory
- The Scala STM library
- Real code
]
???
- Introduction
  - This talk originated with my having already used Scala STM a little at work and
    wanting to investigating it deeper before making a larger use of it.
  - This presentation summarizes what I've learned in my STM research.
- Review agenda
---
layout: false
.left-column[
##The Problem
]
.right-column[
##Share mutable state across multiple concurrent threads of execution

## This is dangerous
- Corruption
- Inconsistency
- Non-deterministic behavior
- Death

"the second you don't respect this, it will kill you"
<img src="GreenBallsOfDeath.jpg" style="width: 300px;" />
]
???
Stop and think about that.

Those words should make you feel uneasy. Look at all the danger words in there.
Words like _concurrency_, _mutable state_, _shared_ are all danger flags.

- Corruption from simultaneous write/read or simultaneous writes.
- Inconnsistency if two values must be modified as a unit but partial updates are visible.
- Race conditions happen when the outcome of a computation depends on order in which different threads execute.

Image and quote from _The Rock_, 1996, with Nicolas Cage and Sean Connery.

---
.left-column[
## The Problem
]
.right-column[
##This problem is difficult...
- to reason about
- to debug
- to test
- to get correct in the first place
- to _keep_ correct over time

##How to solve a difficult problem?
##Avoid it!
- Look for solutions that don't share mutable state
- Actors can help tame concurrency
- Sequence operations on shared data (e.g. single thread executor)
]
???
- To "reason about code" is to be able to look the code and apply thought and logic to come
to an understanding of what the code does and how it behaves
  - It is difficult to reason about concurrency because in addition to the code itself
    we have to consider time and simmultenaity
- Difficult to debug because breakpoints effect timing and concurrency
- Difficult to test because behavior is conditional on timing
- While it is hard, it is *possible* to implement this correctly
- It is harder to keep concurrent code correct then it is to get it right the first time
  - Easy for subsequent maintainers to forget to account for concurrency

- OK, I've satisified my moral obligation to try to talk you out of doing this,
  but you're going to do it anyway so here's how...
---
.left-column[
##Conventional Solution
###Synchronization
]
.right-column[
- Identify _critical sections_ - blocks of code that manipulate shared state

- To enter a criticial section a thread must acquire a mutex

- A thread holds this mutex for the duration of the critical section and other threads that attempt to acquire the mutex block until it is released.

- Intra-thread coordination with ```Object.wait``` and ```Object.notify```

- Concerns
  - Easy to forget to acquire a lock
  - Easy to acquire the wrong lock
  - Easy to forget to `notify` waiting threads
  - Exceptions can cause inconsistent state
  - Deadlocks
  - Priority inversion
]
???
- Mention that Reader/Writer locks can be used to improve performance on read-dominated code
- Mixing mutexes and blocking leads to the potential for deadlocks.
- Mixing mutexes, blocking and thread priorities leads to the potential for priority inversion
  - Recall the Mars Pathfinder mission

- What's not on the list of concerns? Performance.
  - Acquiring a monitor has no significant impact on performance.
  - Don't ever not acquire a monitor because you thinks it's _slow_.
---
.left-column[
##Software Transactional Memory
###A Different Approach to Concurrency
]
.right-column[
##STM Features
- _ACID_ transaction properties for memory operations
  - Atomic, Consistent, Isolated, ~~Durable~~
  - Shared state is accessed within a _transaction_
  - Transactions can be commited, retried or rolled back
- _Optimistic_ execution strategy
  - Let threads access shared state concurrently
  - Detect illegal overlapping operations and retry

## STM in Scala
- Implemented as a library (.jar)
- No external dependencies
- Plain Scala code, no bytecode manipulation
- Provides and API, SPI and a reference implementation
- Java-friendly API included
]
???
- Consider the problem we're trying to solve. It's very reminiscent of
transactional access in relational databases. Maybe applying transactional
techniques to memory is a better solution to concurrency?

- There are two main features of STM
  - Transactions
  - Optimistic concurrency

- ACID
  - Atomic -- All or nothing.
  - Consistent -- Sequence of valid states
  - Isolated -- Concurrent execution same as sequential execution
  - Durable -- Commits stay committed. Not relevant to STM

- Optimistic execution
  - Viable strategy because actual illegal concurrent access is quite rare.
  - Contrast with _pessimistic_ (mutual exclusion) concurrency
  - Sounds like magic but it isn't

- Scala STM is similar to STM implementations in Clojure and Haskell
- Scala STM _may_ end up in the Standard library
---
.left-column[
##Scala STM
###Some code
]
.right-column[
```scala
import scala.concurrent.stm._

private val count = Ref(0)  // count: Ref[Int]
private val data = Ref(Map.empty[Int, String])

def add(id: Int, name: String): Int =
  atomic { implicit txn =>
    data() = data() updated (id, name)
    count() = count() + 1
    count()
  }

def remove(id: Int): Int =
  atomic { implicit txn =>
    data() = data() - id
    count() = count() + 1
    count()
  }
```
- Transactional memory is wrapped inside `Ref`s
- `Ref`s can only be accessed inside `atomic` blocks
- `atomic` supplies a transaction to be used by the `Ref`s
- Access the contents of a `Ref` (read/write) with `()`
- `atomic` blocks can be nested
]
???
- This example shows conccurent access to two pieces of data, a Map
and an integer. The integer keeps track of many operations have been made on the map.
  - `count` and `data` need to be kept in sync.
  - Provide concurrent modification for both adds and deletes
- Only `Ref`s are transactional
  - Not trying to make all memory transactional
  - `Ref` explicitly labels shared state
- Point out that `count` and `data` are `val`s, that is, immutable.
- The contents of `count` and `data` are also immutable
  - This is a 'best practice'
- `Ref`s _contain_ mutable data
  - a `Ref` is a place to keep values that change over time
  - in this case _mutable_ values means that the contents of the `Ref` get
    replaced with new immutable values. It contains a _sequence_ of values over time.
  - together with transactions `Ref`s provide safe concurrent access to shared state
- Hand wave about the syntax at this point. Details coming on a later slide.
- Leverage type system (say what you mean)
  - Shared state is explicity marked as `Ref`s
  - Accidentally using a `Ref` outside of an `atomic` block is a compile time error
  - This helps with maintenance by documenting exactly what is shared and where
---
.left-column[
##Scala STM
###Transactions
]
.right-column[
```scala
import scala.concurrent.stm._

private val count = Ref(0)  // count: Ref[Int]
private val data = Ref(Map.empty[Int, String])

def add(id: Int, name: String): Int =
  atomic { implicit txn =>
    data() = data() updated (id, name)
    count() = count() + 1
    count()
  }

def remove(id: Int): Int =
  atomic { implicit txn =>
    data() = data() - id
    count() = count() + 1
    count()
  }
```
- `atomic` is not `synchronized` - Any number of threads can be inside the `atomic` blocks at the same time
- The transaction
  - prevents corruption due to simultaneous writes
  - detects improper interleaving of threads
  - automatically restarts `atomic` block if necessary
  - automatically rolls back if an exception is thrown
]
???
- Stress that `atomic` is not the same thing as `synchronized`
- Discuss transactions in more depth
  - Attempts to concurrently write the same `Ref` are serialized to prevent corruption
  - At this point just say that STM _can_ detect collisions
  - Any time a transaction detects a collision it retries by starting over at the
    top of the `atomic` block with the new current values.
- There's a better way to do `count() = count() + 1` but this makes the read/write operations clearer right now
- Still hand waving about how this works
---
.left-column[
##Scala STM
###Syntax explained
]
.right-column[
```scala
import scala.concurrent.stm._

private val count = Ref(0)  // count: Ref[Int]
private val data = Ref(Map.empty[Int, String])

def add(id: Int, name: String): Int =
  atomic { implicit txn =>
    data() = data() updated (id, name)
    count() = count() + 1
    count()
  }

def remove(id: Int): Int =
  atomic { implicit txn =>
    data() = data() - id
    count() = count() + 1
    count()
  }
```
- `Ref(0)` is `Ref.apply(0)`
- { implict txn => ... } is function literal with implicit arg
- `atomic` is a function defined in `stm` package object
  - Takes a function from InTxn => Z
  - Provides a transaction and invokes the given function
- What's with all those parens?
  - on the rhs `apply()` - reads the value from the `Ref`
  - on the lhs `update()` - writes a new value to the `Ref`
]
???
- Talk about the syntax
  - Understanding some of the details here will making it easier to follow how STM works
  - This is a *very* common pattern so it is good understand what's going on
- Point out that the `Ref(...)`s are `apply` on the `Ref` companion object. Differentiate these
  from `Ref.apply()` on the `Ref` class.
  - Talk about how classes, traits and companion objects show up in Scaladoc
- Review a little bit about `implicit`
  - An implicit parameter can be supplied by the caller normally
  - If the caller doesn't supply it then the compiler will search the implicit context for a suitable value
- { implict txn => ... } is a function literal taking a single argument (an implicit transaction)
- `atomic` is a function, defined in `stm`, that takes a function from InTxn => Z
  - `atomic` creates a transaction and passes it to the provided function
  - `stm` is a _package object_
  - Importing `stm._` makes it available without the need for `stm.atomic`
- Point out that txn is an argument name with no type
  - The type inferencer can figure out what type it really has
  - Because it's passed to `atomic` which expects an InTx => Z then type type of txn can be inferred
  - You can use any name for the implicit arg but txn is a good nemonic
- Note the actual transaction is hidden behind the InTxn value but you can simply think of InTxn as
  representing the transaction
- The parens are syntactic sugar for
  - `apply()` on the rhs
  - `update()` on the lhs
- Most Scala developers will be familiar with `apply` but `update` maybe new
  - Point out that the `Array` uses `update`
  - .e.g a(1) = "One"
---
.left-column[
##Scala STM
###Sugar-free
]
.right-column[
```scala
import scala.concurrent.stm._

private val count = Ref.apply(0)  // count: Ref[Int]
private val data = Ref.apply(Map.empty[Int, String])

def add(id: Int, name: String): Int =
  stm.atomic({ implicit txn =>
    data.update(data.apply().updated(id, name))
    count.update(count.apply() + 1)
    count.apply()
  })

def remove(id: Int): Int =
  stm.atomic({ implicit txn =>
    data.update(data.apply() - id)
    count.update(count.apply() + 1)
    count.apply()
  })
```
The sugar-free version of the same code
]
???
- This just shows the fully de-sugared Scala code
- There's no reason to dwell on this slide
---
.left-column[
##Scala STM
###Under the covers
]
.right-column[
How does it work? It's all about transactions.

- `apply` and `update` take an `InTxn` as an implicit argument
  - `Ref.apply()(implicit txn: InTxn): A = ...`

- The transaction tracks `Ref`s that have been read so far
  - This is the transaction's _read set_
  - The results of the transaction only depends on the read set

- If another transaction writes to a `Ref` in this transaction's read set
then the transaction has stale state and is rolled back and restarted from the beginning

- Transaction rollback can only happen during an `apply`, `update` or other transaction
method
]
???
- The implicit txn value gets passed to transactional functions (e.g. `apply`) automatically
- The functions are curried
  - You supply the first (empty) parameter set, e.g. `count() = 1`
   - Scala automatically supplies the implicit values for the second parameter set
- It isn't necessarily obvious but the result of the computation depend only on the read set
---
.left-column[
##Scala STM
###Under the covers
]
.right-column[
- This is only a _schematic_ of of what's really going. Don't take this too literally.
- `t?` represent local variables on the stack.
```scala
val data = Ref(Map(1 -> "One", 2 -> "Two", 3 -> "Three")
val count = Ref(4)
```
.pull-left[
<pre><code>
add(4, "Four")
atomic
| begin
| |  read data -> t1
| |  t2 &lt;- t1.updated(...)
| |  write data &lt;- t2
| |  read count -> t3
| |  t4 &lt;- t3 + 1
| |  write count &lt;- t4
| |  read count -> t5
| commit
+-> 5
</code></pre>
]
.pull-right[
<pre><code>
remove(1)
atomic
| begin
| |
| |  read data -> t1
| |  t2 &lt;- t1 - 1
| |  write data &lt;- t2
| rollback "read data stale"
| begin
| |  read data -> t1
| |  t2 &lt;- t1 - 1
| |  write data &lt;- t2
| |  read count -> t3
| |  t4 &lt;- t3 + 1
| |  write count &lt;- t4
| |  read count -> t5
| commit
+-> 6
</code></pre>
]
]
???
- This is only a schematic of what's really going on under the covers
- `t?` represent local stack values
- The code on the left updates the value in `data` before the code on the right.
  - When the code on the right attempts to update `data` it detects the stale state of `data`.
- There's no magic, just accurate and efficient bookeeping
- Don't get too bogged down in the details
---
.left-column[
##Scala STM
]
.right-column[
```scala
import scala.concurrent.stm._

private val count = Ref(0)  // count: Ref[Int]
private val data = Ref(Map.empty[Int, String])

def add(id: Int, name: String): Int =
  atomic { implicit txn =>
    data() = data() updated (id, name)
    count() = count() + 1
    count()
  }

def remove(id: Int): Int =
  atomic { implicit txn =>
    data() = data() - id
    count() = count() + 1
    count()
  }
```
- Recall the code from a few slides ago
- Consider the following statements
  - `data() = data() updated (id, name)`
  - `count() = count() + 1`
- Both of these change the data inside a `Ref` by first
extracting the value, computing a new value and finally storing
the new value back into the `Ref`
- That sounds familiar
]
???
- This code works just fine but it's kind of ugly and can be written
in a slightly more efficient way
- I started with this implementation because it makes the reads and writes explicit
---
.left-column[
##Scala STM
###Transformations
]
.right-column[
```scala
import scala.concurrent.stm._

private val count = Ref(0)  // count: Ref[Int]
private val data = Ref(Map.empty[Int, String])

def add(id: Int, name: String): Int =
  atomic { implicit txn =>
    data transform (_ updated (id, name))
    count transformAndGet (_ + 1)
  }

def remove(id: Int): Int =
  atomic { implicit txn =>
    data transform (_ - id)
    count transformAndGet (_ + 1)
  }
```
- A cleaner implementation
  - `Ref.transform` performs an atomic transformation of the `Ref`s value
  - `Ref.transformAndGet` also returns the `Ref`'s new value
  - `Ref` also provides `getAndTransform`, `swap`, `get`, `*=`, `+=`, `/=`, ...
]
???
- `transform` instead of `map`?
  - Probably to stress that it changes the `Ref`
  - `map` leaves the existing data unchanged and returns a new instance
  - `transform` actually _changes_ whats stored in the `Ref`
- This code accomplishes the same thing as before but is a little cleaner
- Point out use of `_` for default argument
---
.left-column[
##Scala STM
###Views
]
.right-column[
```scala
private val count = Ref(0)  // count: Ref[Int]
private val data = Ref(Map.empty[Int, String])

def add(id: Int, name: String): Int =
  atomic { implicit txn =>
    data transform (_ updated (id, name))
    count transformAndGet (_ + 1)
  }

def remove(id: Int): Int =
  atomic { implicit txn =>
    data transform (_ - id)
    count transformAndGet (_ + 1)
  }

private val countView = count.single
def currentCount = countView()

private val dataView = data.single
def currentData = dataView()
```
- `Ref.single` creates a `View`
  - A convience for single statement operations
  - Can be used outside of a transaction
  - `atomic { implicit t => count() }` &lt;=> `count.single()`
  - `atomic { implicit t => count() = 5 }` &lt;=> `count.single() = 5`
]
???
- `View` has most of the atomic operations as `Ref`
  - `apply`, `update`
  - `transform`, `transformAndGet`, ...
---
.left-column[
##Scala STM
###Views
]
.right-column[
```scala
private val count = Ref(0)  // count: Ref[Int]
private val data = Ref(Map.empty[Int, String])

def add(id: Int, name: String): Int =
  atomic { implicit txn =>
    data transform (_ updated (id, name))
    count transformAndGet (_ + 1)
  }

def remove(id: Int): Int =
  atomic { implicit txn =>
    data transform (_ - id)
    count transformAndGet (_ + 1)
  }

private val countView = count.single
def currentCount = countView()

private val dataView = data.single
def currentData = dataView()
```
- `View` uses a light-weight transaction
  - Less expensive when used outside of a transaction
- A `View` can be used within a normal transaction
  - Participates like any other `Ref`
  - Changes only become visible when the transaction is commited
  - Rolls back
]
???
- `View` _sort of_ creates a light-weight transaction
  - Only when used outside of a real transaction
  - When used within a real transaction it behaves just like a `Ref`
- In this example `count` and `data` could be `View`s and we could do away
  with `countView` and `dataView`. The current approach may help you remember
  that `count` and `data` need to be in transactions and modified atomically.
  Or maybe not.
---
.left-column[
##Scala STM
###A Brief Interlude
]
.right-column[
##So, what do we have so far?

- Shared mutable state is _explicitly marked_
- _No blocking_ so deadlocks and priority inversions are impossible
- Leverage the Scala type system to ensure shared state is only accessed within transactions
- Use Scala language features to simplify code
- Atomicity, consistency and isolation make it easier to reason about code

##All of this makes it _easier_ to write concurrent code and to keep it correct over time.


]
???
- Now that the basics of STM have been covered take a minute to reflect on what
  benefits it brings to the table with respect to conventional concurrency solutions
  - Shared state is explicitly labeled (i.e. `Ref` and `View`)
  - No blocking so deadlocks and priority inversions cannot happen
  - Leverage the Scala type system to prevent accessing shared state outside of transactions
  - Automatic rollback/restart make it easier to reason about code
- All of this helps get concurrent implementations correct and to keep them correct
- Say what you mean style of programming
- Stress that _easier_ does not mean _easy_
  - You still must determine what constitutes shared state
  - You must ensure that everything that belongs in a transaction really is in one
---
.left-column[
##Scala STM
###A Brief Interlude
###Things to keep in mind
]
.right-column[
- Use immutable values inside `Ref`s
  - If you must use mutable data then only hand out immutable snapshots
  - Never expose mutable data outside of an `atomic` block

- Some code paths may execute multiple times
  - Avoid non-repeatable code (e.g. I/O) in `atomic` blocks
  - Handlers can be installed on the transaction to deal with non-repeatable code

- Ordering of `atomic` operations is non-deterministic
  - Isolation insures that result of concurrent atomic operations is the same as if the
    operations ran sequentially
  - The results of a sequence of operations may differ depending on their order
  - STM guarantees that the final result is one of the valid results but not which one
]
???
- Use the banking example from SICP to discuss non-determinism
  - Bank account starts with $100
  - Peter deposits $40
  - Paul withdraw half of the current balance
  - Depending on order the account balance may be $90 or $70
  - Either is valid and the system in consistent because the total money is consserved
---
.left-column[
##Scala STM
###Blocking
]
.right-column[
```scala
private val count = Ref(0)  // count: Ref[Int]
private val data = Ref(Map.empty[Int, String])

def add(id: Int, name: String): Int = ...

def remove(id: Int): Int = ...

def getOrWait(x: Int): String =
  atomic { implicit txn =>
    data() get x getOrElse retry
  }

def getOrWait(x: Int, timeout: Long): Option[String] =
  atomic { implicit txn =>
    data() get x match {
      case s @ Some(_) => s
      case None        => retryFor(timeout); None
    }
  }
```
- `retry` causes `atomic` to rewind and block
  - `atomic` will block and automatically restart when anything in the current read set changes
  - `atomic.withRetryTimeout` will throw `InterruptedException` after timeout
- `retryFor` is like `retry` but
  - Takes a timeout
  - _Returns_ after timeout expires
]
???
- Sometimes you really do want to block
- Use `retry` to indicate that you can't proceed with the current state
  even though the reads and writes have been consistent
- Point out difference between automatic rollback and retry
  - Rollback immediately resumes the computation from the start
  - retry blocks the thread until something pertinate changes
- `retry` will block forever unless something actually changes or 
  - Use `atomic.withRetryTimeout` to supply a timeout
  - Will throw if `InterruptedException` if the timeout expires
  - retry _never_ returns
- `retryFor` takes a timeout and _returns_ when the timeout expires
- The timeouts are cumlative.
- Discuss use of alias in `case s @ Some(_)`
---
.left-column[
##Scala STM
###Blocking
]
.right-column[
```scala
class Fork { val inUse = Ref(false) }

def meal(left: Fork, right: Fork) {
  // thinking
  atomic { implicit txn =>
    if (left.inUse() || right.inUse())
      retry // forks are not both ready, wait
    left.inUse() = true
    right.inUse() = true
  }
  // eating
  atomic { implicit txn =>
    left.inUse() = false
    right.inUse() = false
  }
}
```
- Dining Philolsphers problem
  - Forks are shared between two philosphers
  - A philosopher needs to pick up both forks in order to eat
  - If either fork is in use then block until the state changes
]
???
- A 'real world' example of a blocking algorithm
- This example comes from the Scala STM documentation
- This is only part of the solution but it's the interesting part.
- Note that what values are waited on depends on how far we get before detecting an in-use fork
- Blocking is an integral part of this problem
  - This fine for a small number of threads
  - This doesn't scale well to highly concurrent servers
---
.left-column[
##Scala STM
###Alternatives
]
.right-column[
```scala
val msg =
  atomic { implicit txn =>
    if (x() == 0) retry
    x -= 1
    "took one from x"
  } orAtomic { implicit txn =>
    if (y() == 0) retry
    y -= 1
    "took one from y"
  } orAtomic { implicit txn =>
    if (z() == 0) retry
    z -= 1
    "took one from z"
  }```
- A subsequent `orAtomic` block is executed if `retry` is called
- The final `orAtomic` block above will block until `z` becomes non-zero
]
???
- This example also comes directly from the Scala STM documentation
---
.left-column[
##Scala STM
###TMap & TSet
]
.right-column[
```scala
private val count = Ref(0).single  // count: Ref.View[Int]
private val data = TMap.empty[Int, String].single

def add(id: Int, name: String): Int =
  atomic { implicit txn =>
    data += (id -> name)
    count transformAndGet (_ + 1)
  }

def remove(id: Int): Int =
  atomic { implicit txn =>
    data -= id
    count transformAndGet (_ + 1)
  }

def currentCount = count()

def currentData = data.snapshot
```
- `TMap` and `TSet` provide _mutable_ containers optimized for use within transactions.
- All of their methods require an implicit `InTxn` value
- Using `View`s makes these an almost drop-in replacement for `SynchronizedMap` and `SynchronizedSet`
- Iterators can be used outside of a transaction
  - Provides a picture of the structure at the time the interator was created
]
???
---
.left-column[
##Scala STM
###TMap & TSet
]
.right-column[
```scala
private val count = Ref(0).single  // count: Ref.View[Int]
private val data = TMap.empty[Int, String].single

def add(id: Int, name: String): Int =
  atomic { implicit txn =>
    data += (id -> name)
    count transformAndGet (_ + 1)
  }

def remove(id: Int): Int =
  atomic { implicit txn =>
    data -= id
    count transformAndGet (_ + 1)
  }

def currentCount = count()

def currentData = data.snapshot
```
- `snapshot` returns an immutable `Map` or `Set`
- `clone` returns a new mutable `View`
- `snapshot` and `clone` are O(1)
- Composed internally of mutable hash tries of `Ref`s
  - This provides finer grained control of the read set
  - Multiple transactions may be reading/writing different parts of the internal data structures
    without interference
]
???
- Uses generation numbers and copy-on-write to efficiently 
---
.left-column[
##Scala STM
###Conclussion
###Benefits
]
.right-column[
###Simplifies concurrent programming
  - Explicitly tags shared mutable state
  - Reduces both code and complexity for concurrent problems
  - Simplifies complex blocking without deadlock risks
  - Easier to maintain and keep correct

###Safety
  - Leverage the type system to ensure correct use of shared state
  - Automatically rollsback intermediate changes on exceptions
  - Removes the possibility of deadlocks
]
---
.left-column[
##Scala STM
###Conclusion
###Risks
]
.right-column[
###Correctness
  - STM is essentially a black box
  - Its internals are complicated
  - Ongoing maintenance

###Performance
  - STM is cheap but not free
  - Best results when reads are dominant
    - Reads never cause rollbacks
    - Reads can run concurrently
  - Overall performance assumes rollbacks are rare
    - This is generally the case
    - If atomic blocks are small the likelihood of collisions is small
  - Benchmark and profile for your use cases

###Different
  - Scala STM is not in widespread use
  - May confuse maintainers when they first encounter it
]
???
- Project on Github isn't very active
  - It's finished and really doesn't need anything else
  - Still making bug fixes when necessary
  - Makes builds for new Scala versions
- Show the commit message from the recent deadlock fix
- Demo will show some performance values
---
.left-column[
##Scala STM
###Links
]
.right-column[
- This talk
  - [https://github.com/marcsaegesser/STMPresentation](https://github.com/marcsaegesser/STMPresentation)
- Scala STM
  - [https://nbronson.github.io/scala-stm/intro.html](https://nbronson.github.io/scala-stm/intro.html)
  - [https://github.com/nbronson/scala-stm](https://github.com/nbronson/scala-stm)
- Nathan Bronson - Author of Scala STM
  - [http://purl.stanford.edu/gm457gs5369](http://purl.stanford.edu/gm457gs5369)
- Mars Pathfinder priority inversion
  - [http://research.microsoft.com/en-us/um/people/mbj/Mars_Pathfinder/Mars_Pathfinder.html](http://research.microsoft.com/en-us/um/people/mbj/Mars_Pathfinder/Mars_Pathfinder.html)
- Rich Hickey - Clojure specific but very useful
  - [http://clojure.org/state](http://clojure.org/state)
  - [http://www.infoq.com/presentations/Value-Identity-State-Rich-Hickey](http://www.infoq.com/presentations/Value-Identity-State-Rich-Hickey)
]
---
class: center, middle
# Real Code!
---
    </textarea>
    <script src="http://gnab.github.com/remark/downloads/remark-0.6.5.min.js" type="text/javascript"></script>
    <script type="text/javascript">
      var hljs = remark.highlighter.engine;
    </script>
    <script src="remark.language.js" type="text/javascript"></script>
    <script type="text/javascript">
      var slideshow = remark.create({
          highlightStyle: 'monokai',
          highlightLanguage: 'remark'
        }) ;
    </script>
    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-44561333-1']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
  </body>
</html>
